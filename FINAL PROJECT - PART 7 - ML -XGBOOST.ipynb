{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 7 - ML XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df=pd.read_csv('/Users/nuria/Documents/datasciencecourse/FINAL PROJECT/Happiness_df ready for ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df.drop(columns='Unnamed: 0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happines_score</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Social_support</th>\n",
       "      <th>Life_exp_score</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Gov_trust</th>\n",
       "      <th>Life_exp_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5370</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>1.533524</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.635423</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.315964</td>\n",
       "      <td>73.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.5220</td>\n",
       "      <td>1.482383</td>\n",
       "      <td>1.551122</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.626007</td>\n",
       "      <td>0.355280</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>72.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.5040</td>\n",
       "      <td>1.480633</td>\n",
       "      <td>1.610574</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0.627163</td>\n",
       "      <td>0.475540</td>\n",
       "      <td>0.153527</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.4940</td>\n",
       "      <td>1.564980</td>\n",
       "      <td>1.516912</td>\n",
       "      <td>0.858131</td>\n",
       "      <td>0.620071</td>\n",
       "      <td>0.290549</td>\n",
       "      <td>0.367007</td>\n",
       "      <td>73.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4690</td>\n",
       "      <td>1.443572</td>\n",
       "      <td>1.540247</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.617951</td>\n",
       "      <td>0.245483</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>71.800003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3.4759</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292814</td>\n",
       "      <td>0.253513</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>45.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>3.3123</td>\n",
       "      <td>0.343243</td>\n",
       "      <td>0.522876</td>\n",
       "      <td>0.572383</td>\n",
       "      <td>0.604088</td>\n",
       "      <td>0.235705</td>\n",
       "      <td>0.485542</td>\n",
       "      <td>61.098846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>3.2992</td>\n",
       "      <td>0.425564</td>\n",
       "      <td>1.047835</td>\n",
       "      <td>0.375038</td>\n",
       "      <td>0.377405</td>\n",
       "      <td>0.151349</td>\n",
       "      <td>0.080929</td>\n",
       "      <td>55.617260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>2.8166</td>\n",
       "      <td>0.289083</td>\n",
       "      <td>0.553279</td>\n",
       "      <td>0.208809</td>\n",
       "      <td>0.065609</td>\n",
       "      <td>0.209935</td>\n",
       "      <td>0.111157</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>2.5669</td>\n",
       "      <td>0.300706</td>\n",
       "      <td>0.356434</td>\n",
       "      <td>0.266052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135235</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>52.590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>620 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Happines_score       GDP  Social_support  Life_exp_score   Freedom  \\\n",
       "0            7.5370  1.616463        1.533524        0.796667  0.635423   \n",
       "1            7.5220  1.482383        1.551122        0.792566  0.626007   \n",
       "2            7.5040  1.480633        1.610574        0.833552  0.627163   \n",
       "3            7.4940  1.564980        1.516912        0.858131  0.620071   \n",
       "4            7.4690  1.443572        1.540247        0.809158  0.617951   \n",
       "..              ...       ...             ...             ...       ...   \n",
       "615          3.4759  0.041072        0.000000        0.000000  0.292814   \n",
       "616          3.3123  0.343243        0.522876        0.572383  0.604088   \n",
       "617          3.2992  0.425564        1.047835        0.375038  0.377405   \n",
       "618          2.8166  0.289083        0.553279        0.208809  0.065609   \n",
       "619          2.5669  0.300706        0.356434        0.266052  0.000000   \n",
       "\n",
       "     Generosity  Gov_trust  Life_exp_age  \n",
       "0      0.362012   0.315964     73.099998  \n",
       "1      0.355280   0.400770     72.099998  \n",
       "2      0.475540   0.153527     73.000000  \n",
       "3      0.290549   0.367007     73.800003  \n",
       "4      0.245483   0.382612     71.800003  \n",
       "..          ...        ...           ...  \n",
       "615    0.253513   0.028265     45.200001  \n",
       "616    0.235705   0.485542     61.098846  \n",
       "617    0.151349   0.080929     55.617260  \n",
       "618    0.209935   0.111157     51.000000  \n",
       "619    0.135235   0.001226     52.590000  \n",
       "\n",
       "[620 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def print_score(clf, X_train, y_train, X_test, y_test,train=True):\n",
    "    \"\"\"\n",
    "    Function created to evaluate the performance of the model, calculating MAE, MSE, RMSE and R2\n",
    "    inputs: clf-> model to assess\n",
    "            X_train, X_test\n",
    "            y_train, y_test\n",
    "            train -> Boolean index. If True just show the results regarding the TRAIN set, if False show TEST\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        print(\"Train Result:\\n===========================================\")\n",
    "        MAE_train = metrics.mean_absolute_error(y_train, pred)\n",
    "        MSE_train = metrics.mean_squared_error(y_train, pred)\n",
    "        RMSE_train = np.sqrt(metrics.mean_squared_error(y_train, pred))\n",
    "        R2_train = r2_score(y_train, pred)\n",
    "        \n",
    "        print(f\"MAE: {MAE_train:.4f}\\n\")\n",
    "        print(f\"MSE: {MSE_train:.4f}\\n\")\n",
    "        print(f\"RMSE: {RMSE_train:.4f}\\n\")\n",
    "        print(f\"R^2: {R2_train:.4f}\\n\")\n",
    "        print('================================================================')\n",
    "        cv_scores = cross_val_score(clf, X_train, \n",
    "                            y_train,cv=10, scoring='r2') # Let's define the K and the \n",
    "\n",
    "        print('Cross Validation R2_score for train set: {}'.format(cv_scores.round(2)))\n",
    "        print(\"\\nAverage 10-Fold CV R2_score for train set: {}\".format(np.mean(cv_scores).round(3)))\n",
    "        print()   \n",
    "        \n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        print(\"Test Result:\\n===========================================\")        \n",
    "        MAE_test = metrics.mean_absolute_error(y_test, pred)\n",
    "        MSE_test = metrics.mean_squared_error(y_test, pred)\n",
    "        RMSE_test = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "        R2_test = r2_score(y_test, pred)\n",
    "        \n",
    "        print(f\"MAE: {MAE_test:.4f}\\n\")\n",
    "        print(f\"MSE: {MSE_test:.4f}\\n\")\n",
    "        print(f\"RMSE: {RMSE_test:.4f}\\n\")\n",
    "        print(f\"R^2: {R2_test:.4f}\\n\")\n",
    "        \n",
    "        cv_scores2 = cross_val_score(clf, X_test, \n",
    "                            y_test,cv=10, scoring='r2')\n",
    "        print('Cross Validation R2_score for test set: {}'.format(cv_scores2.round(2)))\n",
    "        print(\"\\nAverage 10-Fold CV R2_score for test set: {}\".format(np.mean(cv_scores2).round(3)))\n",
    "        print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/nuria/opt/anaconda3/envs/NuriaAllwomen/lib/python3.8/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: numpy in /Users/nuria/opt/anaconda3/envs/NuriaAllwomen/lib/python3.8/site-packages (from xgboost) (1.18.5)\r\n",
      "Requirement already satisfied: scipy in /Users/nuria/opt/anaconda3/envs/NuriaAllwomen/lib/python3.8/site-packages (from xgboost) (1.5.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the terminal conda install -c conda -forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = happy_df.Life_exp_age\n",
    "X = happy_df.drop(columns='Life_exp_age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data in a sctructure called DMatrix\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the test and train data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the XGBoost Regressor\n",
    "#linear for regression\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10,booster='gblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=10, base_score=0.5, booster='gblinear',\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.3, gamma=None, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=None, max_depth=5,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=10, n_jobs=0, num_parallel_tree=None, random_state=0,\n",
       "             reg_alpha=10, reg_lambda=0, scale_pos_weight=1, subsample=None,\n",
       "             tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "MAE: 8.0861\n",
      "\n",
      "MSE: 84.8543\n",
      "\n",
      "RMSE: 9.2116\n",
      "\n",
      "R^2: -0.6525\n",
      "\n",
      "================================================================\n",
      "Cross Validation R2_score for train set: [-1.49  0.23 -0.5  -1.25 -0.92 -1.11 -0.52 -1.27 -0.23 -1.36]\n",
      "\n",
      "Average 10-Fold CV R2_score for train set: -0.841\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "MAE: 8.4652\n",
      "\n",
      "MSE: 87.2978\n",
      "\n",
      "RMSE: 9.3433\n",
      "\n",
      "R^2: -0.8635\n",
      "\n",
      "Cross Validation R2_score for test set: [-2.71 -0.92 -0.09 -0.93 -1.29 -0.86 -0.55 -0.64 -1.12 -0.35]\n",
      "\n",
      "Average 10-Fold CV R2_score for test set: -0.947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(xg_reg, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xg_reg, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10,\"booster\":'gblinear'}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.396535</td>\n",
       "      <td>0.024299</td>\n",
       "      <td>40.395891</td>\n",
       "      <td>0.066470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.138416</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>27.131943</td>\n",
       "      <td>0.091543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.791603</td>\n",
       "      <td>0.034023</td>\n",
       "      <td>19.785835</td>\n",
       "      <td>0.115609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.802705</td>\n",
       "      <td>0.071820</td>\n",
       "      <td>15.798014</td>\n",
       "      <td>0.110831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.456269</td>\n",
       "      <td>0.086944</td>\n",
       "      <td>13.452510</td>\n",
       "      <td>0.108981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.961362</td>\n",
       "      <td>0.079732</td>\n",
       "      <td>11.958081</td>\n",
       "      <td>0.120764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.918444</td>\n",
       "      <td>0.081855</td>\n",
       "      <td>10.915811</td>\n",
       "      <td>0.122542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.160535</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>10.158392</td>\n",
       "      <td>0.125817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.597145</td>\n",
       "      <td>0.068386</td>\n",
       "      <td>9.595481</td>\n",
       "      <td>0.126839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.165456</td>\n",
       "      <td>0.062973</td>\n",
       "      <td>9.164242</td>\n",
       "      <td>0.127609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.825278</td>\n",
       "      <td>0.058132</td>\n",
       "      <td>8.824485</td>\n",
       "      <td>0.128837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.550141</td>\n",
       "      <td>0.053623</td>\n",
       "      <td>8.549732</td>\n",
       "      <td>0.131180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.322622</td>\n",
       "      <td>0.049541</td>\n",
       "      <td>8.322570</td>\n",
       "      <td>0.135063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.113897</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>8.114173</td>\n",
       "      <td>0.138985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.901584</td>\n",
       "      <td>0.042246</td>\n",
       "      <td>7.902147</td>\n",
       "      <td>0.143981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.693750</td>\n",
       "      <td>0.037939</td>\n",
       "      <td>7.694561</td>\n",
       "      <td>0.149656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.495491</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>7.496511</td>\n",
       "      <td>0.155781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.309803</td>\n",
       "      <td>0.028975</td>\n",
       "      <td>7.310995</td>\n",
       "      <td>0.162225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.138223</td>\n",
       "      <td>0.024550</td>\n",
       "      <td>7.139554</td>\n",
       "      <td>0.168912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.981305</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>6.982740</td>\n",
       "      <td>0.175796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6.839161</td>\n",
       "      <td>0.016110</td>\n",
       "      <td>6.840671</td>\n",
       "      <td>0.182988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6.710809</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>6.712359</td>\n",
       "      <td>0.190129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.595789</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>6.597349</td>\n",
       "      <td>0.197403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.494905</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>6.496484</td>\n",
       "      <td>0.205801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.405052</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>6.406628</td>\n",
       "      <td>0.214391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.323804</td>\n",
       "      <td>0.004939</td>\n",
       "      <td>6.325301</td>\n",
       "      <td>0.221329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6.244178</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>6.245343</td>\n",
       "      <td>0.221154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.159204</td>\n",
       "      <td>0.035750</td>\n",
       "      <td>6.159836</td>\n",
       "      <td>0.216617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.056355</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>6.056539</td>\n",
       "      <td>0.214798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.943975</td>\n",
       "      <td>0.062322</td>\n",
       "      <td>5.943786</td>\n",
       "      <td>0.214519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.826405</td>\n",
       "      <td>0.068565</td>\n",
       "      <td>5.825915</td>\n",
       "      <td>0.213621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.712465</td>\n",
       "      <td>0.072871</td>\n",
       "      <td>5.711737</td>\n",
       "      <td>0.214854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.602901</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>5.601999</td>\n",
       "      <td>0.216161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.499812</td>\n",
       "      <td>0.075909</td>\n",
       "      <td>5.498793</td>\n",
       "      <td>0.217376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.404448</td>\n",
       "      <td>0.075769</td>\n",
       "      <td>5.403366</td>\n",
       "      <td>0.218410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.317419</td>\n",
       "      <td>0.075058</td>\n",
       "      <td>5.316324</td>\n",
       "      <td>0.219206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.238873</td>\n",
       "      <td>0.074048</td>\n",
       "      <td>5.237811</td>\n",
       "      <td>0.219740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.168628</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>5.167637</td>\n",
       "      <td>0.220011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.106278</td>\n",
       "      <td>0.071818</td>\n",
       "      <td>5.105391</td>\n",
       "      <td>0.220031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.051287</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>5.050528</td>\n",
       "      <td>0.219827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.003038</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>5.002426</td>\n",
       "      <td>0.219430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.960890</td>\n",
       "      <td>0.069179</td>\n",
       "      <td>4.960440</td>\n",
       "      <td>0.218874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.924210</td>\n",
       "      <td>0.068594</td>\n",
       "      <td>4.923929</td>\n",
       "      <td>0.218195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.892390</td>\n",
       "      <td>0.068148</td>\n",
       "      <td>4.892281</td>\n",
       "      <td>0.217430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.864860</td>\n",
       "      <td>0.067828</td>\n",
       "      <td>4.864922</td>\n",
       "      <td>0.216608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.841100</td>\n",
       "      <td>0.067618</td>\n",
       "      <td>4.841330</td>\n",
       "      <td>0.215759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.820639</td>\n",
       "      <td>0.067501</td>\n",
       "      <td>4.821031</td>\n",
       "      <td>0.214907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.803059</td>\n",
       "      <td>0.067461</td>\n",
       "      <td>4.803604</td>\n",
       "      <td>0.214071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.787988</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>4.788677</td>\n",
       "      <td>0.213269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4.775100</td>\n",
       "      <td>0.067561</td>\n",
       "      <td>4.775923</td>\n",
       "      <td>0.212511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0         40.396535        0.024299       40.395891       0.066470\n",
       "1         27.138416        0.020963       27.131943       0.091543\n",
       "2         19.791603        0.034023       19.785835       0.115609\n",
       "3         15.802705        0.071820       15.798014       0.110831\n",
       "4         13.456269        0.086944       13.452510       0.108981\n",
       "5         11.961362        0.079732       11.958081       0.120764\n",
       "6         10.918444        0.081855       10.915811       0.122542\n",
       "7         10.160535        0.074444       10.158392       0.125817\n",
       "8          9.597145        0.068386        9.595481       0.126839\n",
       "9          9.165456        0.062973        9.164242       0.127609\n",
       "10         8.825278        0.058132        8.824485       0.128837\n",
       "11         8.550141        0.053623        8.549732       0.131180\n",
       "12         8.322622        0.049541        8.322570       0.135063\n",
       "13         8.113897        0.046200        8.114173       0.138985\n",
       "14         7.901584        0.042246        7.902147       0.143981\n",
       "15         7.693750        0.037939        7.694561       0.149656\n",
       "16         7.495491        0.033469        7.496511       0.155781\n",
       "17         7.309803        0.028975        7.310995       0.162225\n",
       "18         7.138223        0.024550        7.139554       0.168912\n",
       "19         6.981305        0.020264        6.982740       0.175796\n",
       "20         6.839161        0.016110        6.840671       0.182988\n",
       "21         6.710809        0.012275        6.712359       0.190129\n",
       "22         6.595789        0.008790        6.597349       0.197403\n",
       "23         6.494905        0.004750        6.496484       0.205801\n",
       "24         6.405052        0.005084        6.406628       0.214391\n",
       "25         6.323804        0.004939        6.325301       0.221329\n",
       "26         6.244178        0.014156        6.245343       0.221154\n",
       "27         6.159204        0.035750        6.159836       0.216617\n",
       "28         6.056355        0.051533        6.056539       0.214798\n",
       "29         5.943975        0.062322        5.943786       0.214519\n",
       "30         5.826405        0.068565        5.825915       0.213621\n",
       "31         5.712465        0.072871        5.711737       0.214854\n",
       "32         5.602901        0.075107        5.601999       0.216161\n",
       "33         5.499812        0.075909        5.498793       0.217376\n",
       "34         5.404448        0.075769        5.403366       0.218410\n",
       "35         5.317419        0.075058        5.316324       0.219206\n",
       "36         5.238873        0.074048        5.237811       0.219740\n",
       "37         5.168628        0.072925        5.167637       0.220011\n",
       "38         5.106278        0.071818        5.105391       0.220031\n",
       "39         5.051287        0.070801        5.050528       0.219827\n",
       "40         5.003038        0.069916        5.002426       0.219430\n",
       "41         4.960890        0.069179        4.960440       0.218874\n",
       "42         4.924210        0.068594        4.923929       0.218195\n",
       "43         4.892390        0.068148        4.892281       0.217430\n",
       "44         4.864860        0.067828        4.864922       0.216608\n",
       "45         4.841100        0.067618        4.841330       0.215759\n",
       "46         4.820639        0.067501        4.821031       0.214907\n",
       "47         4.803059        0.067461        4.803604       0.214071\n",
       "48         4.787988        0.067485        4.788677       0.213269\n",
       "49         4.775100        0.067561        4.775923       0.212511"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_re3 = xgb.XGBRegressor(objective ='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10),\n",
    " 'min_child_weight':range(1,6)\n",
    "}\n",
    "xg_reg_tune = GridSearchCV(estimator =xgb.XGBRegressor( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1,n_jobs=4,iid=False, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=5, min_child_weight=1,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=140, n_jobs=None, nthread=4,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=1, seed=27, subsample=0.8,\n",
       "                                    tree_method=None, validate_parameters=False,\n",
       "                                    verbosity=None),\n",
       "             iid=False, n_jobs=4,\n",
       "             param_grid={'max_depth': range(3, 10),\n",
       "                         'min_child_weight': range(1, 6)})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg_tune.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=140, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "             random_state=27, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=27, subsample=0.8, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg_tune.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg_tune_grid=xgb.XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "                 colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
    "                 importance_type='gain', interaction_constraints=None,\n",
    "                 learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
    "                 min_child_weight=2, monotone_constraints=None,\n",
    "                 n_estimators=140, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
    "                 random_state=27, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "                 seed=27, subsample=0.8, tree_method=None,\n",
    "                 validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=140, n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "             random_state=27, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=27, subsample=0.8, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg_tune_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "MAE: 8.0861\n",
      "\n",
      "MSE: 84.8543\n",
      "\n",
      "RMSE: 9.2116\n",
      "\n",
      "R^2: -0.6525\n",
      "\n",
      "================================================================\n",
      "Cross Validation R2_score for train set: [-1.57  0.21 -0.58 -1.24 -0.88 -1.12 -0.52 -1.27 -0.24 -1.36]\n",
      "\n",
      "Average 10-Fold CV R2_score for train set: -0.857\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "MAE: 8.4652\n",
      "\n",
      "MSE: 87.2978\n",
      "\n",
      "RMSE: 9.3433\n",
      "\n",
      "R^2: -0.8635\n",
      "\n",
      "Cross Validation R2_score for test set: [-2.7  -0.92 -0.07 -0.93 -1.32 -0.87 -0.55 -0.63 -1.16 -0.35]\n",
      "\n",
      "Average 10-Fold CV R2_score for test set: -0.949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(xg_reg, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(xg_reg, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after different tries and see that I'm not getting good results I'm tuning, with a large number of\n",
    "#parameters, the xgboost model to get best parameters\n",
    "\n",
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "    'colsample_bytree':[0.4,0.6,0.8], #percentage of features used per tree. High value can lead to overfitting.\n",
    "    'gamma':[0,0.03,0.1,0.3], #controls whether a given node will split based on the expected\n",
    "                              #reduction in loss after the split. \n",
    "                              #A higher value leads to fewer splits. Supported only for \n",
    "                              #tree-based learners.\n",
    "    'min_child_weight':[1.5,6,10],\n",
    "    'learning_rate':[0.1,0.07],#step size shrinkage used to prevent overfitting. Range is [0,1]\n",
    "    'max_depth':[3,5],\n",
    "    'n_estimators':[1000],#number of trees you want to build\n",
    "    'reg_alpha':[1e-5, 1e-2,  0.75],#L1 regularization on leaf weights. A large value leads to more \n",
    "                                    #regularization\n",
    "    'reg_lambda':[1e-5, 1e-2, 0.45],#L2 regularization on leaf weights and is smoother \n",
    "                                    #than L1 regularization\n",
    "    'subsample':[0.6,0.95]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(learning_rate =0.1, n_estimators=1000, max_depth=5,\n",
    "     min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, nthread=6, scale_pos_weight=1, seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1 = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2592 candidates, totalling 12960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   29.3s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:   53.4s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=6)]: Done 601 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done 673 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done 710 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=6)]: Done 749 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=6)]: Done 829 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=6)]: Done 913 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=6)]: Done 956 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=6)]: Done 1001 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=6)]: Done 1046 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=6)]: Done 1093 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=6)]: Done 1189 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=6)]: Done 1289 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=6)]: Done 1340 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=6)]: Done 1393 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=6)]: Done 1501 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=6)]: Done 1556 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=6)]: Done 1613 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=6)]: Done 1670 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=6)]: Done 1729 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=6)]: Done 1849 tasks      | elapsed: 16.7min\n",
      "[Parallel(n_jobs=6)]: Done 1910 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=6)]: Done 1973 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=6)]: Done 2036 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=6)]: Done 2101 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=6)]: Done 2166 tasks      | elapsed: 20.0min\n",
      "[Parallel(n_jobs=6)]: Done 2233 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=6)]: Done 2300 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=6)]: Done 2369 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=6)]: Done 2509 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=6)]: Done 2580 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=6)]: Done 2653 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=6)]: Done 2726 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=6)]: Done 2801 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=6)]: Done 2876 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=6)]: Done 2953 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=6)]: Done 3030 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=6)]: Done 3109 tasks      | elapsed: 28.6min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=6)]: Done 3269 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=6)]: Done 3350 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=6)]: Done 3433 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=6)]: Done 3516 tasks      | elapsed: 32.2min\n",
      "[Parallel(n_jobs=6)]: Done 3601 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=6)]: Done 3686 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=6)]: Done 3773 tasks      | elapsed: 35.0min\n",
      "[Parallel(n_jobs=6)]: Done 3860 tasks      | elapsed: 35.7min\n",
      "[Parallel(n_jobs=6)]: Done 3949 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=6)]: Done 4038 tasks      | elapsed: 36.9min\n",
      "[Parallel(n_jobs=6)]: Done 4129 tasks      | elapsed: 37.9min\n",
      "[Parallel(n_jobs=6)]: Done 4220 tasks      | elapsed: 38.9min\n",
      "[Parallel(n_jobs=6)]: Done 4313 tasks      | elapsed: 39.9min\n",
      "[Parallel(n_jobs=6)]: Done 4406 tasks      | elapsed: 40.7min\n",
      "[Parallel(n_jobs=6)]: Done 4501 tasks      | elapsed: 41.5min\n",
      "[Parallel(n_jobs=6)]: Done 4596 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=6)]: Done 4693 tasks      | elapsed: 43.3min\n",
      "[Parallel(n_jobs=6)]: Done 4790 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=6)]: Done 4889 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=6)]: Done 4988 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=6)]: Done 5089 tasks      | elapsed: 47.1min\n",
      "[Parallel(n_jobs=6)]: Done 5190 tasks      | elapsed: 48.2min\n",
      "[Parallel(n_jobs=6)]: Done 5293 tasks      | elapsed: 49.4min\n",
      "[Parallel(n_jobs=6)]: Done 5396 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=6)]: Done 5501 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=6)]: Done 5606 tasks      | elapsed: 52.4min\n",
      "[Parallel(n_jobs=6)]: Done 5713 tasks      | elapsed: 53.6min\n",
      "[Parallel(n_jobs=6)]: Done 5820 tasks      | elapsed: 54.9min\n",
      "[Parallel(n_jobs=6)]: Done 5929 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=6)]: Done 6038 tasks      | elapsed: 57.3min\n",
      "[Parallel(n_jobs=6)]: Done 6149 tasks      | elapsed: 58.4min\n",
      "[Parallel(n_jobs=6)]: Done 6260 tasks      | elapsed: 60.4min\n",
      "[Parallel(n_jobs=6)]: Done 6373 tasks      | elapsed: 62.7min\n",
      "[Parallel(n_jobs=6)]: Done 6486 tasks      | elapsed: 64.9min\n",
      "[Parallel(n_jobs=6)]: Done 6601 tasks      | elapsed: 66.7min\n",
      "[Parallel(n_jobs=6)]: Done 6716 tasks      | elapsed: 67.6min\n",
      "[Parallel(n_jobs=6)]: Done 6833 tasks      | elapsed: 68.8min\n",
      "[Parallel(n_jobs=6)]: Done 6950 tasks      | elapsed: 70.2min\n",
      "[Parallel(n_jobs=6)]: Done 7069 tasks      | elapsed: 72.6min\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed: 74.3min\n",
      "[Parallel(n_jobs=6)]: Done 7309 tasks      | elapsed: 76.0min\n",
      "[Parallel(n_jobs=6)]: Done 7430 tasks      | elapsed: 78.8min\n",
      "[Parallel(n_jobs=6)]: Done 7553 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=6)]: Done 7676 tasks      | elapsed: 83.8min\n",
      "[Parallel(n_jobs=6)]: Done 7801 tasks      | elapsed: 85.9min\n",
      "[Parallel(n_jobs=6)]: Done 7926 tasks      | elapsed: 89.0min\n",
      "[Parallel(n_jobs=6)]: Done 8053 tasks      | elapsed: 92.2min\n",
      "[Parallel(n_jobs=6)]: Done 8180 tasks      | elapsed: 94.6min\n",
      "[Parallel(n_jobs=6)]: Done 8309 tasks      | elapsed: 96.6min\n",
      "[Parallel(n_jobs=6)]: Done 8438 tasks      | elapsed: 99.6min\n",
      "[Parallel(n_jobs=6)]: Done 8569 tasks      | elapsed: 103.0min\n",
      "[Parallel(n_jobs=6)]: Done 8700 tasks      | elapsed: 105.8min\n",
      "[Parallel(n_jobs=6)]: Done 8833 tasks      | elapsed: 107.8min\n",
      "[Parallel(n_jobs=6)]: Done 8966 tasks      | elapsed: 110.5min\n",
      "[Parallel(n_jobs=6)]: Done 9101 tasks      | elapsed: 114.0min\n",
      "[Parallel(n_jobs=6)]: Done 9236 tasks      | elapsed: 116.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 9373 tasks      | elapsed: 119.0min\n",
      "[Parallel(n_jobs=6)]: Done 9510 tasks      | elapsed: 122.0min\n",
      "[Parallel(n_jobs=6)]: Done 9649 tasks      | elapsed: 126.0min\n",
      "[Parallel(n_jobs=6)]: Done 9788 tasks      | elapsed: 129.7min\n",
      "[Parallel(n_jobs=6)]: Done 9929 tasks      | elapsed: 132.6min\n",
      "[Parallel(n_jobs=6)]: Done 10070 tasks      | elapsed: 137.0min\n",
      "[Parallel(n_jobs=6)]: Done 10213 tasks      | elapsed: 140.2min\n",
      "[Parallel(n_jobs=6)]: Done 10356 tasks      | elapsed: 142.4min\n",
      "[Parallel(n_jobs=6)]: Done 10501 tasks      | elapsed: 145.3min\n",
      "[Parallel(n_jobs=6)]: Done 10646 tasks      | elapsed: 150.5min\n",
      "[Parallel(n_jobs=6)]: Done 10793 tasks      | elapsed: 154.4min\n",
      "[Parallel(n_jobs=6)]: Done 10940 tasks      | elapsed: 157.1min\n",
      "[Parallel(n_jobs=6)]: Done 11089 tasks      | elapsed: 159.9min\n",
      "[Parallel(n_jobs=6)]: Done 11238 tasks      | elapsed: 164.2min\n",
      "[Parallel(n_jobs=6)]: Done 11389 tasks      | elapsed: 167.7min\n",
      "[Parallel(n_jobs=6)]: Done 11540 tasks      | elapsed: 170.2min\n",
      "[Parallel(n_jobs=6)]: Done 11693 tasks      | elapsed: 173.7min\n",
      "[Parallel(n_jobs=6)]: Done 11846 tasks      | elapsed: 177.5min\n",
      "[Parallel(n_jobs=6)]: Done 12001 tasks      | elapsed: 180.4min\n",
      "[Parallel(n_jobs=6)]: Done 12156 tasks      | elapsed: 182.9min\n",
      "[Parallel(n_jobs=6)]: Done 12313 tasks      | elapsed: 186.8min\n",
      "[Parallel(n_jobs=6)]: Done 12470 tasks      | elapsed: 189.4min\n",
      "[Parallel(n_jobs=6)]: Done 12629 tasks      | elapsed: 191.0min\n",
      "[Parallel(n_jobs=6)]: Done 12788 tasks      | elapsed: 193.3min\n",
      "[Parallel(n_jobs=6)]: Done 12949 tasks      | elapsed: 195.8min\n",
      "[Parallel(n_jobs=6)]: Done 12960 out of 12960 | elapsed: 195.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=5, min_child_weight=1,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=1000, n_jobs=None, nthread=6,...\n",
       "                                    tree_method=None, validate_parameters=False,\n",
       "                                    verbosity=None),\n",
       "             iid=False, n_jobs=6,\n",
       "             param_grid={'colsample_bytree': [0.4, 0.6, 0.8],\n",
       "                         'gamma': [0, 0.03, 0.1, 0.3],\n",
       "                         'learning_rate': [0.1, 0.07], 'max_depth': [3, 5],\n",
       "                         'min_child_weight': [1.5, 6, 10],\n",
       "                         'n_estimators': [1000],\n",
       "                         'reg_alpha': [1e-05, 0.01, 0.75],\n",
       "                         'reg_lambda': [1e-05, 0.01, 0.45],\n",
       "                         'subsample': [0.6, 0.95]},\n",
       "             scoring='neg_mean_squared_error', verbose=10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0.1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1.5, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=6, nthread=6, num_parallel_tree=1,\n",
       "             random_state=27, reg_alpha=0.75, reg_lambda=0.45,\n",
       "             scale_pos_weight=1, seed=27, subsample=0.6, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xgboost_reg2=xgb.XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=0.1, gpu_id=-1,\n",
    "             importance_type='gain', interaction_constraints=None,\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=1.5, monotone_constraints=None,\n",
    "             n_estimators=1000, n_jobs=6, nthread=6, num_parallel_tree=1,\n",
    "             random_state=27, reg_alpha=0.75, reg_lambda=0.45,\n",
    "             scale_pos_weight=1, seed=27, subsample=0.6, tree_method=None,\n",
    "             validate_parameters=False, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, gamma=0.1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
       "             min_child_weight=1.5, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=1000, n_jobs=6, nthread=6, num_parallel_tree=1,\n",
       "             random_state=27, reg_alpha=0.75, reg_lambda=0.45,\n",
       "             scale_pos_weight=1, seed=27, subsample=0.6, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xgboost_reg2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "===========================================\n",
      "MAE: 0.1319\n",
      "\n",
      "MSE: 0.0284\n",
      "\n",
      "RMSE: 0.1686\n",
      "\n",
      "R^2: 0.9994\n",
      "\n",
      "================================================================\n",
      "Cross Validation R2_score for train set: [0.92 0.93 0.91 0.87 0.91 0.94 0.91 0.94 0.9  0.87]\n",
      "\n",
      "Average 10-Fold CV R2_score for train set: 0.911\n",
      "\n",
      "Test Result:\n",
      "===========================================\n",
      "MAE: 1.5629\n",
      "\n",
      "MSE: 5.0519\n",
      "\n",
      "RMSE: 2.2476\n",
      "\n",
      "R^2: 0.8922\n",
      "\n",
      "Cross Validation R2_score for test set: [0.71 0.89 0.95 0.87 0.91 0.94 0.95 0.88 0.83 0.93]\n",
      "\n",
      "Average 10-Fold CV R2_score for test set: 0.886\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(Xgboost_reg2, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(Xgboost_reg2, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=Xgboost_reg2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapredict=pd.DataFrame({'Real':y_test,'Predicted':ypred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>74.180000</td>\n",
       "      <td>60.775406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>66.006149</td>\n",
       "      <td>65.158318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>68.300003</td>\n",
       "      <td>66.422348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>61.099998</td>\n",
       "      <td>59.811134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>63.799999</td>\n",
       "      <td>60.549633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>66.400002</td>\n",
       "      <td>66.833023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>64.808945</td>\n",
       "      <td>66.149887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>66.276459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72.099998</td>\n",
       "      <td>72.314514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>55.500000</td>\n",
       "      <td>53.697041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Real  Predicted\n",
       "49   74.180000  60.775406\n",
       "584  66.006149  65.158318\n",
       "82   68.300003  66.422348\n",
       "305  61.099998  59.811134\n",
       "109  63.799999  60.549633\n",
       "..         ...        ...\n",
       "182  66.400002  66.833023\n",
       "495  64.808945  66.149887\n",
       "411  67.000000  66.276459\n",
       "18   72.099998  72.314514\n",
       "428  55.500000  53.697041\n",
       "\n",
       "[205 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df_predictions_plot = datapredict.head(15)#get the 15 first predictions\n",
    "df_predictions_plot.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='black')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "ax = plt.subplot(111)\n",
    "ax.legend(bbox_to_anchor=(1, 1.00))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapredict.to_csv('Best pred XGBoost.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this model takes a long time to execute (3 hours and 26')I'm going to save the model to use it in future ocasions.\n",
    "\n",
    "The are two ways to finalize the models:\n",
    "1-Finalize Your Model with pickle. You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file\n",
    "\n",
    "2-Finalize Your Model with joblib\n",
    "Joblib is part of the SciPy ecosystem and provides utilities for pipelining Python jobs.\n",
    "It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "This can be useful for some machine learning algorithms that require a lot of parameters or store the entire dataset (like K-Nearest Neighbors).\n",
    "\n",
    "In this case I'm going to finalize my model using Pickel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle-mixin\n",
      "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
      "Building wheels for collected packages: pickle-mixin\n",
      "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=5998 sha256=892a0c222aee5217b74574ca5c2f642957f2f3b96c83a16afc57d0ee81b34139\n",
      "  Stored in directory: /Users/nuria/Library/Caches/pip/wheels/2a/a4/6c/83bfbc3b94f1bb43d634b07a6a893fd437a45c58b29aea5142\n",
      "Successfully built pickle-mixin\n",
      "Installing collected packages: pickle-mixin\n",
      "Successfully installed pickle-mixin-1.0.2\n"
     ]
    }
   ],
   "source": [
    "#install the pickle library\n",
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved = 'xgboost_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Xgboost_reg2, open(model_saved, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the future if I need to use this model again:\n",
    "\n",
    "#load the model from the disk\n",
    "#loaded_model = pickle.load(open(model_saved, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
